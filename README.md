# Awesome-DynRF
Complete bibliographic list for Paper: "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field".

# Abstract
Dynamic scene representation and reconstruction have undergone transformative advances in recent years, catalyzed by breakthroughs in neural radiance fields and 3D Gaussian splatting techniques. While initially developed for static environments, these methodologies have rapidly evolved to address the complexities inherent in 4D dynamic scenes through an expansive body of research. Coupled with innovations in differentiable volumetric rendering, these approaches have significantly enhanced the quality of motion representation and dynamic scene reconstruction, thereby garnering substantial attention from the computer vision and graphics communities. This survey presents a systematic analysis of over 200 papers focused on dynamic scene representation using radiance field, spanning the spectrum from implicit neural representations to explicit Gaussian primitives. We categorize and evaluate these works through multiple critical lenses: motion representation paradigms, reconstruction techniques for varied scene dynamics, auxiliary information integration strategies, and regularization approaches that ensure temporal consistency and physical plausibility. We organize diverse methodological approaches under a unified representational framework, concluding with a critical examination of persistent challenges and promising research directions. By providing this comprehensive overview, we aim to establish a definitive reference for researchers entering this rapidly evolving field while offering experienced practitioners a systematic understanding of both conceptual principles and practical frontiers in dynamic scene reconstruction.

# Framework
[Survey](#survey)

[Reconstruction with Rigid Motion](#reconstruction-with-rigid-motion)

[Reconstruction with Articulated Motion](#reconstruction-with-articulated-motion)

[Reconstruction with Nor-rigid Motion](#reconstruction-with-nor-rigid-motion)

[Reconstruction with Hybrid Motion](#reconstructing-with-hybrid-motion)

# Survey
### perprint
| **Paper**                                                                                                                                         | **Conference/Journal** | **Code** | **Type** |
|---------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|----------|----------|
| [Differentiable rendering: A survey](https://arxiv.org/abs/2006.12057)                                                                            | arXiv2020              |          | Survey   |
| [Neural volume rendering: Nerf and beyond](https://arxiv.org/abs/2101.05204)                                                                      | arXiv2020              |          | Survey   |
| [Nerf: Neural radiance field in 3d vision, a comprehensive review](https://arxiv.org/abs/2210.00379)                                              | arXiv2022              |          | Survey   |
| [BeyondPixels: A comprehensive review of the evolution of neural radiance fields](https://ui.adsabs.harvard.edu/abs/2023arXiv230603000S/abstract) | arXiv2023              |          | Survey   |
| [Neural radiance fields: Past, present, and future](https://arxiv.org/abs/2304.10050)                                                             | arXiv2023              |          | Survey   |
| [A survey on 3d gaussian splatting](https://arxiv.org/abs/2401.03890)                                                                             | arXiv2024              |          | Survey   |
| [3d gaussian as a new vision era: A survey](https://ui.adsabs.harvard.edu/abs/2024arXiv240207181F/abstract)                                       | arXiv2024              |          | Survey   |
| [Semantically-aware neural radiance fields for visual scene understanding: A comprehensive review](https://arxiv.org/abs/2402.11141)              | arXiv2024              |          | Survey   |
| [Neural Radiance Field in Urban: A Survey](https://arxiv.org/abs/2404.13816)                                                                      | arXiv2024              |          | Survey   |
| [How nerfs and 3d gaussian splatting are reshaping slam: A survey](https://fabiotosi92.github.io/files/survey-slam.pdf)                           | arXiv2024              |          | Survey   |
| [NeRF in robotics: A survey](https://arxiv.org/abs/2405.01333)                                                                                    | arXiv2024              |          | Survey   |
| [Neural Fields in Robotics: A Survey](https://arxiv.org/abs/2410.20220)                                                                           | arXiv2024              |          | Survey   |

### Paper
| **Paper**                                                                                                                                                                                                                                                                                      | **Conference/Journal**          | **Code** | **Type** |
|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------|----------|----------|
| [Neural fields in visual computing and beyond](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14505)                                                                                                                                                                                      | Computer Graphics Forum 2022    |          | Survey   |
| [3d gaussian splatting as new era: A survey](https://ieeexplore.ieee.org/abstract/document/10521791/?casa_token=0QyGxTRXcuoAAAAA:lcs7VXV5u9xntc4wQtFBjAejlh5aAHHDboeQDN1aQu-SPdVgZRMB1341gfWlt7iKSB7N2Eg2moE)                                                                                  | IEEE TVCG 2024                  |          | Survey   |
| [Recent advances in 3d gaussian splatting](https://link.springer.com/article/10.1007/s41095-024-0436-y)                                                                                                                                                                                        | Computational Visual Media 2024 |          | Survey   |
| [3d gaussian splatting: Survey, technologies, challenges, and opportunities](https://ieeexplore.ieee.org/abstract/document/10870258/?casa_token=sf77HC5Y85sAAAAA:2ukklYMHulxMaKfBV-AH9I0ZpOrnj8tcGv3cAZGp_5d5H7dWAw7yjjIy4RT1Ln5vG5Q0gr7e168)                                                  | IEEE TCSVT 2025                 |          | Survey   |
| [Gaussian splatting: 3d reconstruction and novel view synthesis, a review](https://ieeexplore.ieee.org/abstract/document/10545567/)                                                                                                                                                            | IEEE Access 2024                |          | Survey   |
| [Human 3d avatar modeling with implicit neural representation: A brief survey](https://ieeexplore.ieee.org/abstract/document/10218567/?casa_token=eqD5GGUIgHcAAAAA:kqCuDuxbKgYy5Ndn6Qu2ORYScL62HXkLSNAhcLNyOXZCNwQykukvkhk1mhgoaCos4H_gTrZGG0aJGA)                                             | ICSPS 2022                      |          | Survey   |
| [Benchmarking neural radiance fields for autonomous robots: An overview](https://www.sciencedirect.com/science/article/pii/S0952197624018438?casa_token=lUGEAcODULoAAAAA:RoeYzcwQpI4VUAsp6zAnrwWX7ipHVRyi3V1JsCl9JaKDAHQZdAiATK8sxLBzmtPLlVhyC57awT4)                                          | EAAI 2025                       |          | Survey   |
| [Recent Trends in 3D Reconstruction of General Non-Rigid Scenes](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.15062)                                                                                                                                                                    | CGF 2024                        |          | Survey   |
| [State of the Art in Dense Monocular Non-Rigid 3D Reconstruction](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14774)                                                                                                                                                                   | CGF 2023                        |          | Survey   |
| [Neural radiance fields in the industrial and robotics domain: Applications, research opportunities and use cases](https://www.sciencedirect.com/science/article/pii/S0736584524000978?casa_token=IbEL6IFsBrcAAAAA:N1ijHI5IXgjmtYh0WVADDM4OBXoHsdAMhef9VZohHdghCTMo-8QBBfCvPgbASBFib8yr_ywZRg) | RCIM 2024                       |          | Survey   |
| [A Brief Review on Differentiable Rendering: Recent Advances and Challenges](https://www.mdpi.com/2079-9292/13/17/3546)                                                                                                                                                                        | Electronics 2024                |          | Survey   |

# Reconstruction with Rigid Motion
### perprint
| **Paper**                                                                                                                                   | **Conference/Journal** | **Code** | **Type** |
|---------------------------------------------------------------------------------------------------------------------------------------------|------------------------|----------|----------|
| [Prosgnerf: Progressive dynamic neural scene graph with frequency modulated auto-encoder in urban scenes](https://arxiv.org/abs/2312.09076) | Arxiv 2023             |          | Urban    |

### Paper
| **Paper**                                                                                                                                                                                                                                                                      | **Conference/Journal** | **Code**                                                                       | **Type** |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|--------------------------------------------------------------------------------|----------|
| [Street gaussians: Modeling dynamic urban scenes with gaussian splatting](https://arxiv.org/abs/2401.01339)                                                                                                                                                                    | ECCV 2024              | [Code](https://github.com/zju3dv/street_gaussians)                             | Urban    |
| [Neural scene graphs for dynamic scenes ](http://openaccess.thecvf.com/content/CVPR2021/html/Ost_Neural_Scene_Graphs_for_Dynamic_Scenes_CVPR_2021_paper.html)                                                                                                                  | CVPR 2021              | [Code](https://github.com/princeton-computational-imaging/neural-scene-graphs) | Urban    |
| [Multi-level neural scene graphs for dynamic urban environments](http://openaccess.thecvf.com/content/CVPR2024/html/Fischer_Multi-Level_Neural_Scene_Graphs_for_Dynamic_Urban_Environments_CVPR_2024_paper.html)                                                               | CVPR 2024              | [Code](https://github.com/tobiasfshr/map4d)                                    | Urban    |
| [3d geometry-aware deformable gaussian splatting for dynamic view synthesis](http://openaccess.thecvf.com/content/CVPR2024/html/Lu_3D_Geometry-Aware_Deformable_Gaussian_Splatting_for_Dynamic_View_Synthesis_CVPR_2024_paper.html)                                            | CVPR 2024              | [Code](https://github.com/zhichengLuxx/GaGS)                                   | Urban    |
| [Star: Selfsupervised tracking and reconstruction of rigid objects in motion with neural rendering](http://openaccess.thecvf.com/content/CVPR2021/html/Yuan_STaR_Self-Supervised_Tracking_and_Reconstruction_of_Rigid_Objects_in_Motion_CVPR_2021_paper.html)                  | CVPR 2021              |                                                                                | Indoor   |
| [Panoptic neural fields: A semantic object-aware neural scene representation](http://openaccess.thecvf.com/content/CVPR2022/html/Kundu_Panoptic_Neural_Fields_A_Semantic_Object-Aware_Neural_Scene_Representation_CVPR_2022_paper.html)                                        | CVPR 2022              |                                                                                | Urban    |
| [Hugs: Holistic urban 3d scene understanding via gaussian splatting](http://openaccess.thecvf.com/content/CVPR2024/html/Zhou_HUGS_Holistic_Urban_3D_Scene_Understanding_via_Gaussian_Splatting_CVPR_2024_paper.html)                                                           | CVPR 2024              | [Code](https://github.com/hyzhou404/HUGS)                                      | Urban    |
| [S-nerf: Neural radiance fields for street views](https://openreview.net/forum?id=gx2yJS-ENqI)                                                                                                                                                                                 | ICLR 2023              | [Code](https://github.com/fudan-zvg/S-NeRF)                                    | Urban    |
| [Drivinggaussian: Composite gaussian splatting for surrounding dynamic autonomous driving scenes](http://openaccess.thecvf.com/content/CVPR2024/html/Zhou_DrivingGaussian_Composite_Gaussian_Splatting_for_Surrounding_Dynamic_Autonomous_Driving_Scenes_CVPR_2024_paper.html) | CVPR 2024              | [Code](https://github.com/VDIGPKU/DrivingGaussian)                             | Urban    |
| [Unisim: A neural closedloop sensor simulator](http://openaccess.thecvf.com/content/CVPR2023/html/Yang_UniSim_A_Neural_Closed-Loop_Sensor_Simulator_CVPR_2023_paper.html)                                                                                                      | CVPR 2023              | [Project Site](https://waabi.ai/unisim/)                                       | Urban    |
| [Neurad: Neural rendering for autonomous driving](http://openaccess.thecvf.com/content/CVPR2024/html/Tonderski_NeuRAD_Neural_Rendering_for_Autonomous_Driving_CVPR_2024_paper.html)                                                                                            | CVPR 2024              | [Code](https://github.com/georghess/neurad-studio)                             | Urban    |

# Reconstruction with Articulated Motion
## Human Body
### perprint 
| **Paper**                                                                                                                          | **Conference/Journal** | **Code**                                                      | **Type**   |
|------------------------------------------------------------------------------------------------------------------------------------|------------------------|---------------------------------------------------------------|------------|
| [Generalizable neural performer: Learning robust radiance fields for human novel view synthesis](https://arxiv.org/abs/2204.11798) | arXiv 2022             | [Code](https://github.com/generalizable-neural-performer/gnr) | Human Body |
| [Splatarmor: Articulated gaussian splatting for animatable humans from monocular rgb video](https://arxiv.org/abs/2311.10812)      | arXiv 2023             |                                                               | Human Body |
| [Bags: Building animatable gaussian splatting from a monocular video with diffusion priors](https://arxiv.org/abs/2403.11427)      | arXiv 2024             | [Code](https://github.com/Michaelszj/bags)                    | Human Body |


### Paper
| **Paper**                                                                                                                                                                                                                                                                               | **Conference/Journal** | **Code**                                                        | **Type**            |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|-----------------------------------------------------------------|---------------------|
| [Humannerf: Freeviewpoint rendering of moving people from monocular video](http://openaccess.thecvf.com/content/CVPR2022/html/Weng_HumanNeRF_Free-Viewpoint_Rendering_of_Moving_People_From_Monocular_Video_CVPR_2022_paper.html)                                                       | CVPR 2022              | [Code](https://github.com/chungyiweng/humannerf)                | Human Body          |
| [Animatable neural radiance fields for modeling dynamic human bodies](https://openaccess.thecvf.com/content/ICCV2021/html/Peng_Animatable_Neural_Radiance_Fields_for_Modeling_Dynamic_Human_Bodies_ICCV_2021_paper.html?ref=https://githubhelp.com)                                     | CVPR 2021              | [Code](https://github.com/zju3dv/animatable_nerf)               | Human Body          |
| [Neural human performer: Learning generalizable radiance fields for human performance rendering](https://proceedings.neurips.cc/paper/2021/hash/cf866614b6b18cda13fe699a3a65661b-Abstract.html)                                                                                         | NeurIPS 2021           | [Code](https://github.com/YoungJoongUNC/Neural_Human_Performer) | Human Body          |
| [Vid2avatar: 3d avatar reconstruction from videos in the wild via self-supervised scene decomposition](http://openaccess.thecvf.com/content/CVPR2023/html/Guo_Vid2Avatar_3D_Avatar_Reconstruction_From_Videos_in_the_Wild_via_CVPR_2023_paper.html)                                     | CVPR 2023              |                                                                 | Human Body          |
| [Npc: Neural point characters from video](http://openaccess.thecvf.com/content/ICCV2023/html/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.html)                                                                                                                            | ICCV 2023              | [Code](https://github.com/LemonATsu/NPC-pytorch)                | Human Body          |
| [Tava: Template-free animatable volumetric actors](https://arxiv.org/abs/2206.08929)                                                                                                                                                                                                    | ECCV 2022              | [Code](https://github.com/facebookresearch/tava)                | Human Body          |
| [Neural actor: Neural free-view synthesis of human actors with pose control](https://dl.acm.org/doi/abs/10.1145/3478513.3480528)                                                                                                                                                        | TOG 2021               |                                                                 | Human Body          |
| [Neural articulated radiance field](http://openaccess.thecvf.com/content/ICCV2021/html/Noguchi_Neural_Articulated_Radiance_Field_ICCV_2021_paper.html)                                                                                                                                  | ICCV 2021              | [Code](https://github.com/nogu-atsu/NARF)                       | Human Body          |
| [Neural human performer: Learning generalizable radiance fields for human performance rendering](https://proceedings.neurips.cc/paper/2021/hash/cf866614b6b18cda13fe699a3a65661b-Abstract.html)                                                                                         | NeurIPS 2021           | [Code](https://github.com/YoungJoongUNC/Neural_Human_Performer) | Human Body          |
| [Monohuman: Animatable human neural field from monocular video](http://openaccess.thecvf.com/content/CVPR2023/html/Yu_MonoHuman_Animatable_Human_Neural_Field_From_Monocular_Video_CVPR_2023_paper.html)                                                                                | CVPR 2023              | [Code](https://github.com/Yzmblog/MonoHuman)                    | Human Body          |
| [Structured local radiance fields for human avatar modeling ](http://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Structured_Local_Radiance_Fields_for_Human_Avatar_Modeling_CVPR_2022_paper.html)                                                                                 | CVPR 2022              |                                                                 | Human Body          |
| [Instant-NVR: Instant neural volumetric rendering for human-object interactions from monocular RGBD stream](http://openaccess.thecvf.com/content/CVPR2023/html/Jiang_Instant-NVR_Instant_Neural_Volumetric_Rendering_for_Human-Object_Interactions_From_Monocular_CVPR_2023_paper.html) | CVPR 2023              |                                                                 | Human Body          |
| [Instantavatar: Learning avatars from monocular video in 60 seconds](http://openaccess.thecvf.com/content/CVPR2023/html/Jiang_InstantAvatar_Learning_Avatars_From_Monocular_Video_in_60_Seconds_CVPR_2023_paper.html)                                                                   | CVPR 2023              | [Code](https://github.com/tijiang13/InstantAvatar)              | Human Body          |
| [Snarf: Differentiable forward skinning for animating non-rigid neural implicit shapes](http://openaccess.thecvf.com/content/ICCV2021/html/Chen_SNARF_Differentiable_Forward_Skinning_for_Animating_Non-Rigid_Neural_Implicit_Shapes_ICCV_2021_paper.html)                              | ICCV 2021              |                                                                 | Human Body          |
| [Fast-snarf: A fast deformer for articulated neural fields](https://ieeexplore.ieee.org/abstract/document/10112633/)                                                                                                                                                                    | TPAMI 2023             | [Code](https://github.com/xuchen-ethz/fast-snarf)               | Human Body          |
| [Pina: Learning a personalized implicit neural avatar from a single rgb-d video sequence](http://openaccess.thecvf.com/content/CVPR2022/html/Dong_PINA_Learning_a_Personalized_Implicit_Neural_Avatar_From_a_Single_CVPR_2022_paper.html)                                               | CVPR 2022              |                                                                 | Human Body          |
| [X-avatar: Expressive human avatars](https://openaccess.thecvf.com/content/CVPR2023/html/Shen_X-Avatar_Expressive_Human_Avatars_CVPR_2023_paper.html)                                                                                                                                   | CVPR 2023              | [Code](https://github.com/Skype-line/X-Avatar)                  | Human Body          |
| [Pixel-aligned volumetric avatars](http://openaccess.thecvf.com/content/CVPR2021/html/Raj_Pixel-Aligned_Volumetric_Avatars_CVPR_2021_paper.html)                                                                                                                                        | CVPR 2021              |                                                                 | Human Head          |
| [4k4d: Real-time 4d view synthesis at 4k resolution](https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_4K4D_Real-Time_4D_View_Synthesis_at_4K_Resolution_CVPR_2024_paper.pdf)                                                                                                    | CVPR 2024              |                                                                 | Human Performance   |
| [Real-time deep dynamic characters](https://arxiv.org/pdf/2105.01794)                                                                                                                                                                                                                   | ACM TOG 2021           |                                                                 | Human Performance   |
| [A-nerf: Articulated neural radiance fields for learning human shape, appearance, and pose](https://proceedings.neurips.cc/paper/2021/hash/65fc9fb4897a89789352e211ca2d398f-Abstract.html)                                                                                              | NeurIPS 2021           | [Code](https://github.com/LemonATsu/A-NeRF)                     | Human Body          |
| [Neural actor: Neural free-view synthesis of human actors with pose control](https://arxiv.org/abs/2106.02019)                                                                                                                                                                          | ACM TOG 2021           | [Code](https://github.com/lingjie0206/Neural_Actor_Main_Code)   | Human Body          |
| [Neural articulated radiance field](http://openaccess.thecvf.com/content/ICCV2021/html/Noguchi_Neural_Articulated_Radiance_Field_ICCV_2021_paper.html)                                                                                                                                  | ICCV 2021              | [Code](https://github.com/nogu-atsu/NARF)                       | Human Body          |
| [Nasa neural articulated shape approximation](https://scribblethink.org/Work/Pdfs/deng_NasaNeuralArticulatedShapeApproximation.pdf)                                                                                                                                                     |                        |                                                                 |                     |
| [Lasr: Learning articulated shape reconstruction from a monocular video](http://openaccess.thecvf.com/content/CVPR2021/html/Yang_LASR_Learning_Articulated_Shape_Reconstruction_From_a_Monocular_Video_CVPR_2021_paper.html)                                                            | CVPR 2021              | [Code](https://github.com/google/lasr)                          | Human Body          |
| [Viser: Video-specific surface embeddings for articulated 3d shape reconstruction](https://proceedings.neurips.cc/paper/2021/hash/a11f9e533f28593768ebf87075ab34f2-Abstract.html)                                                                                                       | NeurIPS 2021           | [Code](https://github.com/gengshan-y/viser)                     | Human Body          |
| **ðŸ‘† NeRF-based**                                                                                                                                                                                                                                                                       | **ðŸ‘‡ 3DGS-based**      |                                                                 |                     |
| [Hugs: Human gaussian splats](http://openaccess.thecvf.com/content/CVPR2024/html/Kocabas_HUGS_Human_Gaussian_Splats_CVPR_2024_paper.html)                                                                                                                                               | CVPR 2024              | [Code](https://github.com/apple/ml-hugs)                        | Human Body          |
| [Gart: Gaussian articulated template models](https://openaccess.thecvf.com/content/CVPR2024/html/Lei_GART_Gaussian_Articulated_Template_Models_CVPR_2024_paper.html)                                                                                                                    | CVPR 2024              | [Code](https://github.com/JiahuiLei/GART)                       | Human Body          |
| [Expressive wholebody 3D gaussian avatar](https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05715.pdf)                                                                                                                                                | ECCV 2024              | [Code](https://github.com/mks0601/ExAvatar_RELEASE)             | Human Body and Face |
| [Gauhuman: Articulated gaussian splatting from monocular human videos](http://openaccess.thecvf.com/content/CVPR2024/html/Hu_GauHuman_Articulated_Gaussian_Splatting_from_Monocular_Human_Videos_CVPR_2024_paper.html)                                                                  | CVPR 2024              | [Code](https://github.com/skhu101/GauHuman)                     | Human Body          |
| [Animatable gaussians: Learning pose-dependent gaussian maps for highfidelity human avatar modeling](http://openaccess.thecvf.com/content/CVPR2024/html/Li_Animatable_Gaussians_Learning_Pose-dependent_Gaussian_Maps_for_High-fidelity_Human_Avatar_CVPR_2024_paper.html)              | CVPR 2024              | [Code](https://github.com/lizhe00/AnimatableGaussians)          | Human Body          |
| [Ash: Animatable gaussian splats for efficient and photoreal human rendering](http://openaccess.thecvf.com/content/CVPR2024/html/Pang_ASH_Animatable_Gaussian_Splats_for_Efficient_and_Photoreal_Human_Rendering_CVPR_2024_paper.html)                                                  | CVPR 2024              | [Code](https://github.com/kv2000/ASH)                           | Human Body          |
| [3dgs-avatar: Animatable avatars via deformable 3d gaussian splatting](http://openaccess.thecvf.com/content/CVPR2024/html/Qian_3DGS-Avatar_Animatable_Avatars_via_Deformable_3D_Gaussian_Splatting_CVPR_2024_paper.html)                                                                | CVPR 2024              | [Code](https://github.com/mikeqzy/3dgs-avatar-release)          | Human Body          |
| [Animatable gaussians: Learning pose-dependent gaussian maps for highfidelity human avatar modeling](http://openaccess.thecvf.com/content/CVPR2024/html/Li_Animatable_Gaussians_Learning_Pose-dependent_Gaussian_Maps_for_High-fidelity_Human_Avatar_CVPR_2024_paper.html)              | CVPR 2024              | [Code](https://github.com/lizhe00/AnimatableGaussians)          | Human Body          |
| [Gaussianavatar: Towards realistic human avatar modeling from a single video via animatable 3d gaussians](http://openaccess.thecvf.com/content/CVPR2024/html/Hu_GaussianAvatar_Towards_Realistic_Human_Avatar_Modeling_from_a_Single_Video_CVPR_2024_paper.html)                        | CVPR 2024              | [Code](https://github.com/aipixel/GaussianAvatar)               | Human Body          |
| [Splattingavatar: Realistic real-time human avatars with mesh-embedded gaussian splatting](http://openaccess.thecvf.com/content/CVPR2024/html/Shao_SplattingAvatar_Realistic_Real-Time_Human_Avatars_with_Mesh-Embedded_Gaussian_Splatting_CVPR_2024_paper.html)                        | CVPR 2024              | [Code](https://github.com/initialneil/SplattingAvatar)          | Human Body and Face |
| [Gomavatar: Efficient animatable human modeling from monocular video using gaussians-on-mesh](https://openaccess.thecvf.com/content/CVPR2024/html/Wen_GoMAvatar_Efficient_Animatable_Human_Modeling_from_Monocular_Video_Using_Gaussians-on-Mesh_CVPR_2024_paper.html)                  | CVPR 2024              | [Code](https://github.com/wenj/GoMAvatar)                       | Human Body          |
| [Moda: Modeling deformable 3d objects from casual videos](https://link.springer.com/article/10.1007/s11263-024-02310-5)                                                                                                                                                                 | IJCV 2024              | [Code](https://github.com/ChaoyueSong/MoDA)                     | Human Body          |


## Hand
### Paper
| **Paper**                                                                                                                                                                                                                                                                      | **Conference/Journal** | **Code**                                            | **Type** |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|-----------------------------------------------------|----------|
| [Lisa: Learning implicit shape and appearance of hands](http://openaccess.thecvf.com/content/CVPR2022/html/Corona_LISA_Learning_Implicit_Shape_and_Appearance_of_Hands_CVPR_2022_paper.html)                                                                                   | CVPR 2022              |                                                     | Hand     |
| [Livehand: Real-time and photorealistic neural hand rendering](http://openaccess.thecvf.com/content/ICCV2023/html/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.html)                                                                     | ICCV 2023              | [Code](https://github.com/amundra15/livehand)       | Hand     |
| [URhand: Universal relightable hands](http://openaccess.thecvf.com/content/CVPR2024/html/Chen_URHand_Universal_Relightable_Hands_CVPR_2024_paper.html)                                                                                                                         | CVPR 2024              | [Code](https://github.com/facebookresearch/goliath) | Hand     |
| [Relightablehands: Efficient neural relighting of articulated hand models](http://openaccess.thecvf.com/content/CVPR2023/html/Iwase_RelightableHands_Efficient_Neural_Relighting_of_Articulated_Hand_Models_CVPR_2023_paper.html)                                              | CVPR 2023              |                                                     | Hand     | 
| [HandRT: Simultaneous hand shape and appearance reconstruction with pose tracking from monocular RGB-d video](https://ieeexplore.ieee.org/abstract/document/10938919/?casa_token=ufZHfP3HGXEAAAAA:pFNAjIELvIyYjNgF8a2gYp-srVDmbYAbMlm2MOgQhHAB5fXUzGoECJsgvEjq_zGEI75Ju8IjH8U) | TPAMI 2025             | [Code](https://github.com/pmkalshetti/handrt)       | Hand     |
| [Whatâ€™s in your hands? 3d reconstruction of generic objects in hands](http://openaccess.thecvf.com/content/CVPR2022/html/Ye_Whats_in_Your_Hands_3D_Reconstruction_of_Generic_Objects_in_CVPR_2022_paper.html)                                                                  | CVPR 2022              | [Code](https://github.com/JudyYe/shelf-sup-mesh)    | Hand     |


## Animal
### Paper
| **Paper**                                                                                                                                                                                                                              | **Conference/Journal** | **Code**                                                 | **Type** |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|----------------------------------------------------------|----------|
| [3d menagerie: Modeling the 3d shape and pose of animals](http://openaccess.thecvf.com/content_cvpr_2017/html/Zuffi_3D_Menagerie_Modeling_CVPR_2017_paper.html)                                                                        | CVPR 2017              |                                                          | Animal   |
| [Who left the dogs out? 3d animal reconstruction with expectation maximization in the loop](https://link.springer.com/chapter/10.1007/978-3-030-58621-8_12)                                                                            | ECCV 2022              | [Code](https://github.com/benjiebob/WLDO)                | Animal   |
| [Reconstructing animatable categories from videos](http://openaccess.thecvf.com/content/CVPR2023/html/Yang_Reconstructing_Animatable_Categories_From_Videos_CVPR_2023_paper.html)                                                      | CVPR 2023              | [Code](https://github.com/gengshan-y/rac)                | Animal   |
| [Lassie: Learning articulated shapes from sparse image ensemble via 3d part discovery](https://proceedings.neurips.cc/paper_files/paper/2022/hash/6274d57365d7a6be06e58cad30d1b9da-Abstract-Conference.html)                           | NeurIPS 2022           | [Code](https://github.com/google/hi-lassie)              | Animal   |
| [Artemis: articulated neural pets with appearance and motion synthesis](https://arxiv.org/abs/2202.05628)                                                                                                                              | SIGGRAPH 2022          | [Code](https://github.com/HaiminLuo/Artemis)             | Animal   |
| [Banmo: Building animatable 3d neural models from many casual videos](http://openaccess.thecvf.com/content/CVPR2022/html/Yang_BANMo_Building_Animatable_3D_Neural_Models_From_Many_Casual_Videos_CVPR_2022_paper.html)                 | CVPR 2022              | [Code](https://github.com/facebookresearch/banmo)        | Animal   |
| [Magicpony: Learning articulated 3d animals in the wild](http://openaccess.thecvf.com/content/CVPR2023/html/Wu_MagicPony_Learning_Articulated_3D_Animals_in_the_Wild_CVPR_2023_paper.html)                                             | CVPR 2023              | [Code](https://github.com/elliottwu/MagicPony)           | Animal   |
| [Common pets in 3d: Dynamic new-view synthesis of real-life deformable categories](http://openaccess.thecvf.com/content/CVPR2023/html/Sinha_Common_Pets_in_3D_Dynamic_New-View_Synthesis_of_Real-Life_Deformable_CVPR_2023_paper.html) | CVPR 2023              | [Code](https://github.com/facebookresearch/cop3d)        | Animal   |
| [Animal avatars: Reconstructing animatable 3D animals from casual videos](https://link.springer.com/chapter/10.1007/978-3-031-72986-7_16)                                                                                              | ECCV 2024              | [Code](https://github.com/facebookresearch/AnimalAvatar) | Animal   |


## Other Objects
### Paper
| **Paper**                                                                                                                                                                                                                                | **Conference/Journal** | **Code**                                      | **Type** |
|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|-----------------------------------------------|----------|
| [Clanerf: Category-level articulated neural radiance field](https://ieeexplore.ieee.org/abstract/document/9812272/?casa_token=6_rU_yhrMM4AAAAA:QSMnTVBIHNt2TQIhGn7ISTYTSTjT-y9ceMgpusOT4qS3ojid4X0mSxCkhun2vgpPFpvMXmAzRIGnaQ)           | ICRA 2022              |                                               | Object   |
| [Paris: Part-level reconstruction and motion analysis for articulated objects](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.html) | ICCV 2023              | [Code](https://github.com/3dlg-hcvc/PARIS)    | Object   |
| [Leia: Latent view-invariant embeddings for implicit 3d articulation](https://link.springer.com/chapter/10.1007/978-3-031-72640-8_12)                                                                                                    | ECCV 2024              |                                               | Object   |
| [Reacto: Reconstructing articulated objects from a single video](http://openaccess.thecvf.com/content/CVPR2024/html/Song_REACTO_Reconstructing_Articulated_Objects_from_a_Single_Video_CVPR_2024_paper.html)                             | CVPR 2024              | [Code](https://github.com/ChaoyueSong/REACTO) | Object   |


### perprint
| **Paper**                                                                                                                       | **Conference/Journal** | **Code**                                  | **Type** |
|---------------------------------------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------|----------|
| [Artgs: Building interactable replicas of complex articulated objects via gaussian splatting](https://arxiv.org/abs/2502.19459) | arXiv 2025             | [Code](https://github.com/YuLiu-LY/ArtGS) | Object   |


# Reconstruction with Nor-rigid Motion
## 4D Spacetime
### Paper
| **Paper**                                                                                                                                                                                                 | **Conference/Journal** | **Code**                                                    | **Type**       |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------------------------|----------------|
| [Space-time neural irradiance fields for free-viewpoint video](http://openaccess.thecvf.com/content/CVPR2021/html/Xian_Space-Time_Neural_Irradiance_Fields_for_Free-Viewpoint_Video_CVPR_2021_paper.html) | CVPR 2021              | [Code](https://github.com/wxian3/video-nerf)                | General Motion |
| [Real-time photorealistic dynamic scene representation and rendering with 4d gaussian splatting](https://arxiv.org/abs/2310.10642)                                                                        | ICLR 2024              | [Code](https://github.com/fudan-zvg/4d-gaussian-splatting)  | General Motion |
| [Neural 3d video synthesis from multi-view video](http://openaccess.thecvf.com/content/CVPR2022/html/Li_Neural_3D_Video_Synthesis_From_Multi-View_Video_CVPR_2022_paper.html)                             | CVPR 2022              | [Code](https://github.com/facebookresearch/Neural_3D_Video) | General Motion |
| [Suds: Scalable urban dynamic scenes](http://openaccess.thecvf.com/content/CVPR2023/html/Turki_SUDS_Scalable_Urban_Dynamic_Scenes_CVPR_2023_paper.html)                                                   | CVPR 2023              | [Code](https://github.com/hturki/suds)                      | Urban          |
| [Neural volumes: Learning dynamic renderable volumes from images](https://arxiv.org/abs/1906.07751)                                                                                                       | ACM TOG 2023           | [Code](https://github.com/facebookresearch/neuralvolumes)   | Object         |
| [Neural surface reconstruction of dynamic scenes with monocular rgbd camera](https://proceedings.neurips.cc/paper_files/paper/2022/hash/06a52a54c8ee03cd86771136bc91eb1f-Abstract-Conference.html)        | NeurIPS 2022           | [Code](https://ustc3dv.github.io/ndr/)                      | Object         |


## Canonical Space with Deformation Field
### Paper
| **Paper**                                                                                                                                                                                                                                         | **Conference/Journal** | **Code**                                                    | **Type**       |
|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------------------------|----------------|
| [D-nerf: Neural radiance fields for dynamic scenes](https://openaccess.thecvf.com/content/CVPR2021/html/Pumarola_D-NeRF_Neural_Radiance_Fields_for_Dynamic_Scenes_CVPR_2021_paper.html?ref=labelbox.ghost.io)                                     | CVPR 2021              | [Code](https://github.com/albertpumarola/D-NeRF)            | Object         |
| [Nerfies: Deformable neural radiance fields](http://openaccess.thecvf.com/content/ICCV2021/html/Park_Nerfies_Deformable_Neural_Radiance_Fields_ICCV_2021_paper.html)                                                                              | ICCV 2021              | [Code](https://github.com/google/nerfies)                   | General Motion |
| [Hypernerf: a higher-dimensional representation for topologically varying neural radiance fields](https://arxiv.org/abs/2106.13228)                                                                                                               | ACM TOG 2021           | [Code](https://github.com/google/hypernerf)                 | General Motion |
| [4d gaussian splatting for real-time dynamic scene rendering](http://openaccess.thecvf.com/content/CVPR2024/html/Wu_4D_Gaussian_Splatting_for_Real-Time_Dynamic_Scene_Rendering_CVPR_2024_paper.html)                                             | CVPR 2024              | [Code](https://github.com/hustvl/4DGaussians)               | General Motion |
| [Deformable 3d gaussians for high-fidelity monocular dynamic scene reconstruction](http://openaccess.thecvf.com/content/CVPR2024/html/Yang_Deformable_3D_Gaussians_for_High-Fidelity_Monocular_Dynamic_Scene_Reconstruction_CVPR_2024_paper.html) | CVPR 2024              | [Code](https://github.com/ingra14m/Deformable-3D-Gaussians) | General Motion |
| [MoDGS: Dynamic Gaussian Splatting from Causuallycaptured Monocular Videos](https://modgs.github.io/static/paper.pdf)                                                                                                                             | ICLR 2025              | [Code](https://github.com/MobiusLqm/MoDGS)                  | General Motion |
| [Neural surface reconstruction of dynamic scenes with monocular rgbd camera](https://proceedings.neurips.cc/paper_files/paper/2022/hash/06a52a54c8ee03cd86771136bc91eb1f-Abstract-Conference.html)                                                | NeurIPS 2022           | [Code](https://github.com/USTC3DV/NDR-code)                 | Object         |


## Frame-to-Frame Flow Field
## Point Tracking
## Factorization

# Reconstructing with Hybrid Motion
